{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b288a91c",
   "metadata": {},
   "source": [
    "### SOP EVALUATION USING ML ALGORITHMS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2a1eb5",
   "metadata": {},
   "source": [
    "##### Reading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "ac4d360f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('SOPs Dataset.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "66253206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sno</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To the Admissions Committee of University of B...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Committee of the University of Toron...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0  Unnamed: 1                                         Unnamed: 2  \\\n",
       "0        NaN         NaN                                                NaN   \n",
       "1        Sno         NaN                                                SOP   \n",
       "2        NaN         NaN                                                NaN   \n",
       "3          1         NaN  To the Admissions Committee of University of B...   \n",
       "4          2         NaN  Admission Committee of the University of Toron...   \n",
       "\n",
       "   Unnamed: 3 Unnamed: 4  \n",
       "0         NaN        NaN  \n",
       "1         NaN      Label  \n",
       "2         NaN        NaN  \n",
       "3         NaN        NaN  \n",
       "4         NaN        NaN  "
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20acb136",
   "metadata": {},
   "source": [
    "##### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "52f9d3c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>SOP</th>\n",
       "      <th>Column4</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sno</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To the Admissions Committee of University of B...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Committee of the University of Toron...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dear Admissions Committee,\\n\\nI am Nisha Gupta...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dear Admissions Committee,\\n\\nI am Anirudh Kap...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dear Admissions Committee,\\n\\nI am Priyanka Pa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>799</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dear Admissions Committee,\\n\\nI am Arjun Mehta...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dear Admissions Committee,\\n\\nI am Meera Sharm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>821 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Column1  Column2                                                SOP  \\\n",
       "0       NaN      NaN                                                NaN   \n",
       "1       Sno      NaN                                                SOP   \n",
       "2       NaN      NaN                                                NaN   \n",
       "3         1      NaN  To the Admissions Committee of University of B...   \n",
       "4         2      NaN  Admission Committee of the University of Toron...   \n",
       "..      ...      ...                                                ...   \n",
       "816     796      NaN  Dear Admissions Committee,\\n\\nI am Nisha Gupta...   \n",
       "817     797      NaN  Dear Admissions Committee,\\n\\nI am Anirudh Kap...   \n",
       "818     798      NaN  Dear Admissions Committee,\\n\\nI am Priyanka Pa...   \n",
       "819     799      NaN  Dear Admissions Committee,\\n\\nI am Arjun Mehta...   \n",
       "820     800      NaN  Dear Admissions Committee,\\n\\nI am Meera Sharm...   \n",
       "\n",
       "     Column4  Label  \n",
       "0        NaN    NaN  \n",
       "1        NaN  Label  \n",
       "2        NaN    NaN  \n",
       "3        NaN    NaN  \n",
       "4        NaN    NaN  \n",
       "..       ...    ...  \n",
       "816      NaN      1  \n",
       "817      NaN      1  \n",
       "818      NaN      1  \n",
       "819      NaN      1  \n",
       "820      NaN      1  \n",
       "\n",
       "[821 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "column_labels = ['Column1', 'Column2', 'SOP','Column4','Label']\n",
    "df.columns = column_labels\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "8e2ce29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOP</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SOP</td>\n",
       "      <td>Label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To the Admissions Committee of University of B...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Admission Committee of the University of Toron...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>Dear Admissions Committee,\\n\\nI am Nisha Gupta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>Dear Admissions Committee,\\n\\nI am Anirudh Kap...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>Dear Admissions Committee,\\n\\nI am Priyanka Pa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>Dear Admissions Committee,\\n\\nI am Arjun Mehta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>Dear Admissions Committee,\\n\\nI am Meera Sharm...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>821 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   SOP  Label\n",
       "0                                                  NaN    NaN\n",
       "1                                                  SOP  Label\n",
       "2                                                  NaN    NaN\n",
       "3    To the Admissions Committee of University of B...    NaN\n",
       "4    Admission Committee of the University of Toron...    NaN\n",
       "..                                                 ...    ...\n",
       "816  Dear Admissions Committee,\\n\\nI am Nisha Gupta...      1\n",
       "817  Dear Admissions Committee,\\n\\nI am Anirudh Kap...      1\n",
       "818  Dear Admissions Committee,\\n\\nI am Priyanka Pa...      1\n",
       "819  Dear Admissions Committee,\\n\\nI am Arjun Mehta...      1\n",
       "820  Dear Admissions Committee,\\n\\nI am Meera Sharm...      1\n",
       "\n",
       "[821 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dropping unwanted columns and displaying the dataset\n",
    "columns_to_drop = ['Column1', 'Column2', 'Column4']\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "64a87ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOP</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To the Admissions Committee of University of B...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Admission Committee of the University of Toron...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dear Admissions Committee of McGill University...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>To the Esteemed Admissions Panel of McMaster U...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dear Admissions Committee of the University of...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 SOP Label\n",
       "3  To the Admissions Committee of University of B...   NaN\n",
       "4  Admission Committee of the University of Toron...   NaN\n",
       "5  Dear Admissions Committee of McGill University...   NaN\n",
       "6  To the Esteemed Admissions Panel of McMaster U...   NaN\n",
       "7  Dear Admissions Committee of the University of...   NaN"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the first 3 since it has no values\n",
    "df = df.drop(df.index[:3])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "bd1061de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOP</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To the Admissions Committee of University of B...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Admission Committee of the University of Toron...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dear Admissions Committee of McGill University...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To the Esteemed Admissions Panel of McMaster U...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dear Admissions Committee of the University of...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 SOP Label\n",
       "0  To the Admissions Committee of University of B...   NaN\n",
       "1  Admission Committee of the University of Toron...   NaN\n",
       "2  Dear Admissions Committee of McGill University...   NaN\n",
       "3  To the Esteemed Admissions Panel of McMaster U...   NaN\n",
       "4  Dear Admissions Committee of the University of...   NaN"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset the index to 0\n",
    "df = df.reset_index(drop=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "5f6ee3fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOP</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To the Admissions Committee of University of B...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Admission Committee of the University of Toron...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dear Admissions Committee of McGill University...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To the Esteemed Admissions Panel of McMaster U...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dear Admissions Committee of the University of...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>To the Respected Admissions Board of the Unive...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dear Admissions Committee at the University of...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>To the Esteemed Admissions Panel of McMaster U...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dear Admissions Board of Queen's University,\\n...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>To the Admission Committee of the University o...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 SOP  Label\n",
       "0  To the Admissions Committee of University of B...    NaN\n",
       "1  Admission Committee of the University of Toron...    NaN\n",
       "2  Dear Admissions Committee of McGill University...    NaN\n",
       "3  To the Esteemed Admissions Panel of McMaster U...    NaN\n",
       "4  Dear Admissions Committee of the University of...    NaN\n",
       "5  To the Respected Admissions Board of the Unive...    NaN\n",
       "6  Dear Admissions Committee at the University of...    NaN\n",
       "7  To the Esteemed Admissions Panel of McMaster U...    NaN\n",
       "8  Dear Admissions Board of Queen's University,\\n...    NaN\n",
       "9  To the Admission Committee of the University o...    NaN"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace all 1's with 0 in the 'Label' column\n",
    "df['Label'] = df['Label'].replace(1, 0)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "148316e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOP</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To the Admissions Committee of University of B...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Admission Committee of the University of Toron...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dear Admissions Committee of McGill University...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To the Esteemed Admissions Panel of McMaster U...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dear Admissions Committee of the University of...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>To the Visa Officer,\\nCanada High Commission, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>To the Visa Officer,\\nCanada High Commission, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>To the Visa Officer,\\nCanada High Commission, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>To the Visa Officer,\\nCanada High Commission, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>To the Visa Officer,\\nCanada High Commission, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  SOP  Label\n",
       "0   To the Admissions Committee of University of B...    1.0\n",
       "1   Admission Committee of the University of Toron...    1.0\n",
       "2   Dear Admissions Committee of McGill University...    1.0\n",
       "3   To the Esteemed Admissions Panel of McMaster U...    1.0\n",
       "4   Dear Admissions Committee of the University of...    1.0\n",
       "..                                                ...    ...\n",
       "95  To the Visa Officer,\\nCanada High Commission, ...    0.0\n",
       "96  To the Visa Officer,\\nCanada High Commission, ...    0.0\n",
       "97  To the Visa Officer,\\nCanada High Commission, ...    0.0\n",
       "98  To the Visa Officer,\\nCanada High Commission, ...    0.0\n",
       "99  To the Visa Officer,\\nCanada High Commission, ...    0.0\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace all NaN values with 1 in the 'Label' column\n",
    "df['Label'].fillna(1, inplace=True)\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "77b45d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with null values in the 'SOP' column\n",
    "df = df.dropna(subset=['SOP'])\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "de4f1dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(804, 2)"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "daa38c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOP</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>804 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SOP  Label\n",
       "0    False  False\n",
       "1    False  False\n",
       "2    False  False\n",
       "3    False  False\n",
       "4    False  False\n",
       "..     ...    ...\n",
       "799  False  False\n",
       "800  False  False\n",
       "801  False  False\n",
       "802  False  False\n",
       "803  False  False\n",
       "\n",
       "[804 rows x 2 columns]"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for missing values\n",
    "df.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "483f2937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values and printing columns with null values and their respective counts\n",
    "null_values = df.isnull().sum()\n",
    "for column, count in null_values.items():\n",
    "    if count > 0:\n",
    "        print(f'Column: {column}, Null Count: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "68a38b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0     630\n",
       "0.0     173\n",
       "11.0      1\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if the dataset is biased or not\n",
    "df.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "26eee10b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    631\n",
       "0.0    173\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing one label 11.0 with 1.0\n",
    "df['Label'] = df['Label'].replace([11.0],1.0)\n",
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "911dca17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    631\n",
       "0.0    173\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38585530",
   "metadata": {},
   "source": [
    "Here we can understand that the count of approved SOP's are so high in number when compared to those which are rejected. \n",
    "Which creates a bias problem in the dataset.\n",
    "So we need to perform augmentation to balance the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7e9989",
   "metadata": {},
   "source": [
    "##### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "399b9a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\roysi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Function to replace rejected SOP words with its synonyms and create augmented SOP\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "import random\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def get_synonyms(word):\n",
    "    synonyms = []\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.append(lemma.name())\n",
    "    return synonyms\n",
    "\n",
    "def synonym_replacement(text, n=1):\n",
    "    words = text.split()\n",
    "    augmented_texts = []\n",
    "    for _ in range(n):\n",
    "        augmented_words = []\n",
    "        for word in words:\n",
    "            synonyms = get_synonyms(word)\n",
    "            if synonyms:\n",
    "                synonym = random.choice(synonyms)\n",
    "                augmented_words.append(synonym)\n",
    "            else:\n",
    "                augmented_words.append(word)\n",
    "        augmented_text = ' '.join(augmented_words)\n",
    "        augmented_texts.append(augmented_text)\n",
    "    return str(augmented_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "7e36b6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\AppData\\Local\\Temp\\ipykernel_12588\\264420576.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rejected_sop[\"SOP\"] = aug_texts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(977, 2)"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1st iteration for augmentation SOP's with label 0\n",
    "rejected_sop = df[df['Label'] == 0]\n",
    "\n",
    "aug_texts = []\n",
    "for text in rejected_sop[\"SOP\"]:\n",
    "    aug_text = synonym_replacement(text)\n",
    "    aug_texts.append(aug_text)\n",
    "\n",
    "rejected_sop[\"SOP\"] = aug_texts\n",
    "rejected_sop.head()\n",
    "\n",
    "df = pd.concat([df, rejected_sop], ignore_index=True)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "26719e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 SOP  \\\n",
      "79  ['To the visa Officer, Canada highschool Commission, fresh Delhi. SUBJECT: AN coating for survey permission honor Officer, My describe follow Vivek Malhotra, and one atomic_number_95 antiophthalmic_factor network designer At Tc with A Passion_of_Christ for desegregate technology into healthcare. piece my academic carrying_into_action stand at 68%, my IELTS score of 6.0 get alas fallen short of the threshold, conduct to my application for the bach of scientific_discipline IN health IP at the university of the Fraser vale be not accepted. contempt this setback, my committedness to the line_of_business of wellness information_processing stay steadfast. My professional_person experience At TCS, arise insure and efficient mesh solution for health_care providers, have groom Pine_Tree_State for the challenge and chance in health informatics. 1 personify determine to improve my terminology technique and reapply for the program, axerophthol I believe the university of the Fraser valley be the nonesuch site to surrogate my emergence atomic_number_49 this active field. The programâ€™s comprehensive programme and the universityâ€™s inscription to scholarly_person success come_across with my educational aspirations. i plan to carry_on heighten my skill and contribute to visualise atomic_number_85 TC that aline with wellness information_processing until atomic_number_53 fulfill the prerequisite for this respect program. I be aspirer for amp future_tense chance to join the university of the Fraser vale and agnise my potential_drop inward wellness informatics.']   \n",
      "\n",
      "    Label  \n",
      "79    0.0  \n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_colwidth', None):\n",
    "    print(rejected_sop.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "51f79f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting the index\n",
    "df = df.reset_index(level=0)\n",
    "df['index'] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "3ea01738",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\AppData\\Local\\Temp\\ipykernel_12588\\4275085621.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rejected_sop_1[\"SOP\"] = texts\n"
     ]
    }
   ],
   "source": [
    "#2nd iteration for augmentation the SOP's with label 0\n",
    "rejected_sop_1 = df[df['Label'] == 0] \n",
    "rejected_sop_1.SOP.count()\n",
    "\n",
    "texts = []\n",
    "for text in rejected_sop_1[\"SOP\"]:\n",
    "    aug_text = synonym_replacement(str(text))\n",
    "    texts.append(aug_text)\n",
    "\n",
    "rejected_sop_1[\"SOP\"] = texts\n",
    "rejected_sop.head()\n",
    "\n",
    "df = pd.concat([df, rejected_sop], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "1a4a03cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appending the augmented SOP's to the dataframe\n",
    "new_sop =[]\n",
    "for row in df.SOP:\n",
    "    if type(row) == str:\n",
    "        new_sop.append(row)\n",
    "    else:\n",
    "        concatenated_series = pd.concat(row)\n",
    "        new_sop.append(', '.join(concatenated_series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "902e4b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    631\n",
       "0.0    519\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total SOP Count after augmentation\n",
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68083148",
   "metadata": {},
   "source": [
    "##### NLP Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "b39a564f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "99ce83c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "15075892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing punctuation's\n",
    "def remove_punctuations(text):\n",
    "    punctuations = string.punctuation\n",
    "    return text.translate(str.maketrans('','',punctuations))\n",
    "df['SOP'] = df['SOP'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "761a5fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Clean_sop'] = df['SOP'].apply(lambda x: remove_punctuations(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "a992e2be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1145    dear admission Committee iodin be Nisha Gupta ...\n",
       "1146    dear access Committee one MA Anirudh Kapoor de...\n",
       "1147    pricy admittance Committee I be Priyanka Patel...\n",
       "1148    darling priceofadmission Committee 1 ArtiumMag...\n",
       "1149    dear admission Committee i be Meera Sharma typ...\n",
       "Name: Clean_sop, dtype: object"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Clean_sop.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "867efde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "07902f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "150728a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'these', 'until', \"should've\", 'not', 'hasn', 'because', 'out', 'once', 'shan', 'own', 'having', 'is', 'now', 'ours', 'was', 'they', 'those', 'most', 'himself', 'as', \"weren't\", 'only', 'itself', 'wouldn', 'before', 'ourselves', 'have', 'yourselves', 'to', 'it', 'me', 'off', 'if', \"you're\", 'yourself', 'will', 'we', 'that', 'below', 'my', \"you'd\", 'too', 'than', 'been', 'with', 'few', 'here', \"shouldn't\", 'ma', \"wasn't\", 'won', 'which', 'into', 'under', 'over', \"hasn't\", \"shan't\", 'how', 'she', 'll', 'didn', 'whom', 'do', 'mustn', 'a', 'very', 'for', 'who', 'them', \"mightn't\", 'weren', \"you've\", 'theirs', 'so', \"you'll\", \"won't\", \"it's\", 'y', 'does', 'd', 'his', \"couldn't\", \"isn't\", 'don', 'both', \"didn't\", 'some', 'has', \"wouldn't\", 'there', 'aren', 'o', 'mightn', 'by', 'did', 'doesn', 'where', 'are', 'more', 'couldn', 'being', 'had', 'no', 'her', 'other', 'then', 'myself', 'at', \"hadn't\", 'doing', 'shouldn', 'up', 'any', 'down', 'your', \"mustn't\", \"haven't\", 'on', \"doesn't\", 'its', 'be', 've', 'him', \"that'll\", 'while', \"needn't\", 'haven', 'nor', 'were', 'and', 'further', 'herself', 'but', 'between', 'in', 'such', 'or', 'ain', 'our', 'yours', 'needn', 't', 'themselves', 'their', 'just', 'am', 'what', 's', 'wasn', 'isn', 'again', 'why', 'against', 'when', \"she's\", 're', 'i', \"don't\", 'each', 'he', 'of', 'from', 'same', 'an', 'm', 'during', 'hadn', 'you', 'through', 'should', 'above', 'can', 'the', 'hers', 'after', 'this', \"aren't\", 'about', 'all'}\n"
     ]
    }
   ],
   "source": [
    "print(STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "b3807db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stopwords\n",
    "def remove_stopwords(text):\n",
    "    return \" \".join(word for word in text.split() if word not in STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "26ba44c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Clean_sop\"] = df[\"Clean_sop\"].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "34a7dcf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>SOP</th>\n",
       "      <th>Label</th>\n",
       "      <th>Clean_sop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"dear admission Committee, iodin be Nisha Gup...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dear admission Committee iodin Nisha Gupta A c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"dear access Committee, one MA Anirudh Kapoor...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dear access Committee one MA Anirudh Kapoor de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"pricy admittance Committee, I be Priyanka Pa...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pricy admittance Committee I Priyanka Patel A ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"darling price_of_admission Committee, 1 Arti...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>darling priceofadmission Committee 1 ArtiumMag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"dear admission Committee, i be Meera Sharma,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dear admission Committee Meera Sharma typeA gi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                                SOP  Label  \\\n",
       "1145    NaN  [\"dear admission Committee, iodin be Nisha Gup...    0.0   \n",
       "1146    NaN  [\"dear access Committee, one MA Anirudh Kapoor...    0.0   \n",
       "1147    NaN  [\"pricy admittance Committee, I be Priyanka Pa...    0.0   \n",
       "1148    NaN  [\"darling price_of_admission Committee, 1 Arti...    0.0   \n",
       "1149    NaN  [\"dear admission Committee, i be Meera Sharma,...    0.0   \n",
       "\n",
       "                                              Clean_sop  \n",
       "1145  dear admission Committee iodin Nisha Gupta A c...  \n",
       "1146  dear access Committee one MA Anirudh Kapoor de...  \n",
       "1147  pricy admittance Committee I Priyanka Patel A ...  \n",
       "1148  darling priceofadmission Committee 1 ArtiumMag...  \n",
       "1149  dear admission Committee Meera Sharma typeA gi...  "
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "571381cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower casing the SOP\n",
    "df['Clean_sop'] = df['Clean_sop'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "58534e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>SOP</th>\n",
       "      <th>Label</th>\n",
       "      <th>Clean_sop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"dear admission Committee, iodin be Nisha Gup...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dear admission committee iodin nisha gupta a c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"dear access Committee, one MA Anirudh Kapoor...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dear access committee one ma anirudh kapoor de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"pricy admittance Committee, I be Priyanka Pa...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pricy admittance committee i priyanka patel a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"darling price_of_admission Committee, 1 Arti...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>darling priceofadmission committee 1 artiummag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"dear admission Committee, i be Meera Sharma,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dear admission committee meera sharma typea gi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                                SOP  Label  \\\n",
       "1145    NaN  [\"dear admission Committee, iodin be Nisha Gup...    0.0   \n",
       "1146    NaN  [\"dear access Committee, one MA Anirudh Kapoor...    0.0   \n",
       "1147    NaN  [\"pricy admittance Committee, I be Priyanka Pa...    0.0   \n",
       "1148    NaN  [\"darling price_of_admission Committee, 1 Arti...    0.0   \n",
       "1149    NaN  [\"dear admission Committee, i be Meera Sharma,...    0.0   \n",
       "\n",
       "                                              Clean_sop  \n",
       "1145  dear admission committee iodin nisha gupta a c...  \n",
       "1146  dear access committee one ma anirudh kapoor de...  \n",
       "1147  pricy admittance committee i priyanka patel a ...  \n",
       "1148  darling priceofadmission committee 1 artiummag...  \n",
       "1149  dear admission committee meera sharma typea gi...  "
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "eefca5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\roysi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       [to, admissions, committee, university, britis...\n",
      "1       [admission, committee, university, toronto, gr...\n",
      "2       [dear, admissions, committee, mcgill, universi...\n",
      "3       [to, esteemed, admissions, panel, mcmaster, un...\n",
      "4       [dear, admissions, committee, university, toro...\n",
      "                              ...                        \n",
      "1145    [dear, admission, committee, iodin, nisha, gup...\n",
      "1146    [dear, access, committee, one, ma, anirudh, ka...\n",
      "1147    [pricy, admittance, committee, i, priyanka, pa...\n",
      "1148    [darling, priceofadmission, committee, 1, arti...\n",
      "1149    [dear, admission, committee, meera, sharma, ty...\n",
      "Name: tokenized_text, Length: 1150, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing the SOP text\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "df['tokenized_text'] = df['Clean_sop'].apply(lambda x: word_tokenize(x))\n",
    "print(df['tokenized_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "cde9884c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "a9987c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizing the tokenized word with appropriate Parts Of Speech tagging \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to perform POS tagging and lemmatization\n",
    "def pos_mapping_lemmatization(text):\n",
    "    pos_tags = pos_tag(text)\n",
    "    \n",
    "    lemmatized_words = []\n",
    "    for word, tag in pos_tags:\n",
    "        if tag.startswith('N'):\n",
    "            pos = 'n'\n",
    "        elif tag.startswith('V'):\n",
    "            pos = 'v'\n",
    "        elif tag.startswith('R'):\n",
    "            pos = 'r'\n",
    "        else:\n",
    "            pos = 'n'\n",
    "        \n",
    "        lemma = lemmatizer.lemmatize(word, pos)\n",
    "        lemmatized_words.append(lemma)\n",
    "    \n",
    "    lemmatized_text = ' '.join(lemmatized_words)\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "ce84375a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>SOP</th>\n",
       "      <th>Label</th>\n",
       "      <th>Clean_sop</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>To the Admissions Committee of University of B...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>to admissions committee university british col...</td>\n",
       "      <td>[to, admissions, committee, university, britis...</td>\n",
       "      <td>to admission committee university british colu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Admission Committee of the University of Toron...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>admission committee university toronto greetin...</td>\n",
       "      <td>[admission, committee, university, toronto, gr...</td>\n",
       "      <td>admission committee university toronto greetin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Dear Admissions Committee of McGill University...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>dear admissions committee mcgill university my...</td>\n",
       "      <td>[dear, admissions, committee, mcgill, universi...</td>\n",
       "      <td>dear admission committee mcgill university my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>To the Esteemed Admissions Panel of McMaster U...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>to esteemed admissions panel mcmaster universi...</td>\n",
       "      <td>[to, esteemed, admissions, panel, mcmaster, un...</td>\n",
       "      <td>to esteem admission panel mcmaster university ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Dear Admissions Committee of the University of...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>dear admissions committee university toronto m...</td>\n",
       "      <td>[dear, admissions, committee, university, toro...</td>\n",
       "      <td>dear admission committee university toronto my...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                                SOP  Label  \\\n",
       "0    0.0  To the Admissions Committee of University of B...    1.0   \n",
       "1    1.0  Admission Committee of the University of Toron...    1.0   \n",
       "2    2.0  Dear Admissions Committee of McGill University...    1.0   \n",
       "3    3.0  To the Esteemed Admissions Panel of McMaster U...    1.0   \n",
       "4    4.0  Dear Admissions Committee of the University of...    1.0   \n",
       "\n",
       "                                           Clean_sop  \\\n",
       "0  to admissions committee university british col...   \n",
       "1  admission committee university toronto greetin...   \n",
       "2  dear admissions committee mcgill university my...   \n",
       "3  to esteemed admissions panel mcmaster universi...   \n",
       "4  dear admissions committee university toronto m...   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  [to, admissions, committee, university, britis...   \n",
       "1  [admission, committee, university, toronto, gr...   \n",
       "2  [dear, admissions, committee, mcgill, universi...   \n",
       "3  [to, esteemed, admissions, panel, mcmaster, un...   \n",
       "4  [dear, admissions, committee, university, toro...   \n",
       "\n",
       "                                     lemmatized_text  \n",
       "0  to admission committee university british colu...  \n",
       "1  admission committee university toronto greetin...  \n",
       "2  dear admission committee mcgill university my ...  \n",
       "3  to esteem admission panel mcmaster university ...  \n",
       "4  dear admission committee university toronto my...  "
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lemmatized_text'] = df['tokenized_text'].apply(lambda x: pos_mapping_lemmatization(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a9c820",
   "metadata": {},
   "source": [
    "#### MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "ef2e5836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "e5e98342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Validation Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(df['lemmatized_text'], df['Label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "e5e98342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Dataset: 1150\n",
      "Training Set: 920\n",
      "Validation Set: 230\n"
     ]
    }
   ],
   "source": [
    "# Train and Validation set distribution of the dataset\n",
    "lenSOP = df['lemmatized_text'].count()\n",
    "print(f'Total Dataset: {lenSOP}')\n",
    "print(f'Training Set: {len(X_train)}')\n",
    "print(f'Validation Set: {len(X_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760c186f",
   "metadata": {},
   "source": [
    "RandomForestClassifier using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "a2e74fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train data: (920, 4603)\n"
     ]
    }
   ],
   "source": [
    "# Using Count Vectorizer to convert text to vectors\n",
    "vectorizer_lda = CountVectorizer(min_df=2)  # Adjust min_df as needed\n",
    "vectorizer_lda.fit(X_train)\n",
    "X_train_cv = vectorizer_lda.transform(X_train)\n",
    "X_val_cv = vectorizer_lda.transform(X_val)\n",
    "print(f'Shape of train data: {X_train_cv.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "4a31bc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier using CountVectorizer\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Set</th>\n",
       "      <th>Validation Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.860870</td>\n",
       "      <td>0.839130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.799051</td>\n",
       "      <td>0.771605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.998024</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_score</th>\n",
       "      <td>0.887522</td>\n",
       "      <td>0.871080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Training Set  Validation Set\n",
       "Accuracy       0.860870        0.839130\n",
       "Precision      0.799051        0.771605\n",
       "Recall         0.998024        1.000000\n",
       "F1_score       0.887522        0.871080"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model Training and Prediction for Count Vectorizer using random forest classifier\n",
    "clf_cv = RandomForestClassifier(max_depth=2, max_leaf_nodes=3, n_estimators=20)\n",
    "clf_cv.fit(X_train_cv, y_train)\n",
    "y_pred_cv_train = clf_cv.predict(X_train_cv)\n",
    "y_pred_cv_val = clf_cv.predict(X_val_cv)\n",
    "\n",
    "# Model Evaluation for RFC\n",
    "metrics = {'Training Set':\n",
    "           {'Accuracy':accuracy_score(y_train, y_pred_cv_train),\n",
    "            'Precision':precision_score(y_train, y_pred_cv_train),\n",
    "            'Recall':recall_score(y_train, y_pred_cv_train),\n",
    "            'F1_score':f1_score(y_train, y_pred_cv_train)},\n",
    "           \n",
    "           'Validation Set':\n",
    "           {'Accuracy':accuracy_score(y_val, y_pred_cv_val),\n",
    "            'Precision':precision_score(y_val, y_pred_cv_val),\n",
    "            'Recall':recall_score(y_val, y_pred_cv_val),\n",
    "            'F1_score':f1_score(y_val, y_pred_cv_val)}\n",
    "            }\n",
    "\n",
    "metricDf = pd.DataFrame.from_dict(metrics)\n",
    "print('RandomForestClassifier using CountVectorizer')\n",
    "display(metricDf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320622f7",
   "metadata": {},
   "source": [
    "RandomForestClassifier using TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "32914585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train data: (920, 6037)\n"
     ]
    }
   ],
   "source": [
    "# Using TF-IDF vectorizer for converting text to vectors\n",
    "vectorizer_lsa = TfidfVectorizer()\n",
    "vectorizer_lsa.fit(X_train)\n",
    "X_train_tfidf = vectorizer_lsa.transform(X_train)\n",
    "X_val_tfidf = vectorizer_lsa.transform(X_val)\n",
    "print(f'Shape of train data: {X_train_tfidf.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "d0f075ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier using TfidfVectorizer and TruncatedSVD\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Set</th>\n",
       "      <th>Validation Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.882609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.836093</td>\n",
       "      <td>0.822368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.998024</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_score</th>\n",
       "      <td>0.909910</td>\n",
       "      <td>0.902527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Training Set  Validation Set\n",
       "Accuracy       0.891304        0.882609\n",
       "Precision      0.836093        0.822368\n",
       "Recall         0.998024        1.000000\n",
       "F1_score       0.909910        0.902527"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model Training and Prediction for TF-IDF using random forest classifier\n",
    "clf_tfidf = RandomForestClassifier(max_depth=2, max_leaf_nodes=3, n_estimators=20)\n",
    "clf_tfidf.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf_train = clf_tfidf.predict(X_train_tfidf)\n",
    "y_pred_tfidf_val = clf_tfidf.predict(X_val_tfidf)\n",
    "\n",
    "# Model Evaluation for TF-IDF\n",
    "metrics = {'Training Set':\n",
    "           {'Accuracy':accuracy_score(y_train, y_pred_tfidf_train),\n",
    "            'Precision':precision_score(y_train, y_pred_tfidf_train),\n",
    "            'Recall':recall_score(y_train, y_pred_tfidf_train),\n",
    "            'F1_score':f1_score(y_train, y_pred_tfidf_train)},\n",
    "           \n",
    "           'Validation Set':\n",
    "           {'Accuracy':accuracy_score(y_val, y_pred_tfidf_val),\n",
    "            'Precision':precision_score(y_val, y_pred_tfidf_val),\n",
    "            'Recall':recall_score(y_val, y_pred_tfidf_val),\n",
    "            'F1_score':f1_score(y_val, y_pred_tfidf_val)}\n",
    "            }\n",
    "\n",
    "metricDf = pd.DataFrame.from_dict(metrics)\n",
    "print('RandomForestClassifier using TfidfVectorizer and TruncatedSVD')\n",
    "display(metricDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71535596",
   "metadata": {},
   "source": [
    "##### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "6a9e8ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'max_depth': 20, 'max_leaf_nodes': 30, 'n_estimators': 100}\n",
      "Training set score: 0.9869565217391304\n",
      "Test set score: 0.9478260869565217\n"
     ]
    }
   ],
   "source": [
    "# Using Hyperparameter tuning to find best values for the random forest classifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [25, 50, 100, 150],\n",
    "    'max_depth': [3, 6, 9, 20, 30],\n",
    "    'max_leaf_nodes': [3, 6, 9, 20, 30]\n",
    "}\n",
    "\n",
    "rf_clf = RandomForestClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(rf_clf, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "best_rf_clf = RandomForestClassifier(**grid_search.best_params_)\n",
    "best_rf_clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"Training set score:\", best_rf_clf.score(X_train_tfidf, y_train))\n",
    "print(\"Test set score:\", best_rf_clf.score(X_val_tfidf, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a04a20",
   "metadata": {},
   "source": [
    "RandomForestClassifier using CountVectorizer and LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "ee5e4f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after dimensionality reduction of train data: (920, 3000)\n"
     ]
    }
   ],
   "source": [
    "# Specify the number of topics for LDA\n",
    "num_topics_lda = 3000  # You can adjust this number as needed\n",
    "lda = LatentDirichletAllocation(n_components=num_topics_lda, random_state=42)\n",
    "lda.fit(X_train_cv)  # Fit LDA model for training data\n",
    "X_train_topics_lda = lda.fit_transform(X_train_cv)\n",
    "X_val_topics_lda = lda.transform(X_val_cv)  # Transform test data into topic distributions\n",
    "print(f'Shape after dimensionality reduction of train data: {X_train_topics_lda.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "2544933c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training and Prediction for LDA\n",
    "clf_lda = RandomForestClassifier(max_depth=20, max_leaf_nodes=30, n_estimators=25)\n",
    "clf_lda.fit(X_train_topics_lda, y_train)\n",
    "y_pred_lda_train = clf_lda.predict(X_train_topics_lda)\n",
    "y_pred_lda_val = clf_lda.predict(X_val_topics_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "5b274ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier using CountVectorizer and LatentDirichletAllocation\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Set</th>\n",
       "      <th>Validation Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.910870</td>\n",
       "      <td>0.882609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.914062</td>\n",
       "      <td>0.845070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.924901</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_score</th>\n",
       "      <td>0.919450</td>\n",
       "      <td>0.898876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Training Set  Validation Set\n",
       "Accuracy       0.910870        0.882609\n",
       "Precision      0.914062        0.845070\n",
       "Recall         0.924901        0.960000\n",
       "F1_score       0.919450        0.898876"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model Evaluation for LDA\n",
    "metrics = {'Training Set':\n",
    "           {'Accuracy':accuracy_score(y_train, y_pred_lda_train),\n",
    "            'Precision':precision_score(y_train, y_pred_lda_train),\n",
    "            'Recall':recall_score(y_train, y_pred_lda_train),\n",
    "            'F1_score':f1_score(y_train, y_pred_lda_train)},\n",
    "           \n",
    "           'Validation Set':\n",
    "           {'Accuracy':accuracy_score(y_val, y_pred_lda_val),\n",
    "            'Precision':precision_score(y_val, y_pred_lda_val),\n",
    "            'Recall':recall_score(y_val, y_pred_lda_val),\n",
    "            'F1_score':f1_score(y_val, y_pred_lda_val)}\n",
    "            }\n",
    "\n",
    "metricDf = pd.DataFrame.from_dict(metrics)\n",
    "print('RandomForestClassifier using CountVectorizer and LatentDirichletAllocation')\n",
    "display(metricDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81c93e5",
   "metadata": {},
   "source": [
    "RandomForestClassifier using TfidfVectorizer and TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "88e787ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after dimensionality reduction of train data: (920, 920)\n"
     ]
    }
   ],
   "source": [
    "# Specify the number of components for LSA\n",
    "num_components_lsa = 3000  # You can adjust this number as needed\n",
    "lsa = TruncatedSVD(n_components=num_components_lsa, random_state=42)\n",
    "lsa.fit(X_train_tfidf)  # Fit LSA model for training data\n",
    "X_train_components_lsa = lsa.fit_transform(X_train_tfidf)\n",
    "X_val_components_lsa = lsa.transform(X_val_tfidf)  # Transform test data into components\n",
    "print(f'Shape after dimensionality reduction of train data: {X_train_components_lsa.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "35ef7dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training and Prediction for LSA\n",
    "clf_lsa = RandomForestClassifier(max_depth=20, max_leaf_nodes=30, n_estimators=25)\n",
    "clf_lsa.fit(X_train_components_lsa, y_train)\n",
    "y_pred_lsa_train = clf_lsa.predict(X_train_components_lsa)\n",
    "y_pred_lsa_val = clf_lsa.predict(X_val_components_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "1fcb3821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier using TfidfVectorizer and TruncatedSVD\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Set</th>\n",
       "      <th>Validation Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.979348</td>\n",
       "      <td>0.826087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.967370</td>\n",
       "      <td>0.763975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.996047</td>\n",
       "      <td>0.984000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_score</th>\n",
       "      <td>0.981500</td>\n",
       "      <td>0.860140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Training Set  Validation Set\n",
       "Accuracy       0.979348        0.826087\n",
       "Precision      0.967370        0.763975\n",
       "Recall         0.996047        0.984000\n",
       "F1_score       0.981500        0.860140"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model Evaluation for LSA\n",
    "metrics = {'Training Set':\n",
    "           {'Accuracy':accuracy_score(y_train, y_pred_lsa_train),\n",
    "            'Precision':precision_score(y_train, y_pred_lsa_train),\n",
    "            'Recall':recall_score(y_train, y_pred_lsa_train),\n",
    "            'F1_score':f1_score(y_train, y_pred_lsa_train)},\n",
    "           \n",
    "           'Validation Set':\n",
    "           {'Accuracy':accuracy_score(y_val, y_pred_lsa_val),\n",
    "            'Precision':precision_score(y_val, y_pred_lsa_val),\n",
    "            'Recall':recall_score(y_val, y_pred_lsa_val),\n",
    "            'F1_score':f1_score(y_val, y_pred_lsa_val)}\n",
    "            }\n",
    "\n",
    "metricDf = pd.DataFrame.from_dict(metrics)\n",
    "print('RandomForestClassifier using TfidfVectorizer and TruncatedSVD')\n",
    "display(metricDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "c8c45edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling ml model, vectorizer and dimensionality reduction models\n",
    "import pickle\n",
    "\n",
    "f = open('Deployment\\Models\\\\vectorizerTFIDF.pkl', 'wb')\n",
    "pickle.dump(vectorizer_lsa, f)\n",
    "f.close()\n",
    "\n",
    "f = open('Deployment\\Models\\\\vectorizerCV.pkl', 'wb')\n",
    "pickle.dump(vectorizer_lda, f)\n",
    "f.close()\n",
    "\n",
    "f = open('Deployment\\Models\\LDA.pkl', 'wb')\n",
    "pickle.dump(lda, f)\n",
    "f.close()\n",
    "\n",
    "f = open('Deployment\\Models\\TSVD.pkl', 'wb')\n",
    "pickle.dump(lsa, f)\n",
    "f.close()\n",
    "\n",
    "f = open('Deployment\\Models\\RF_CV_LDA.pkl', 'wb')\n",
    "pickle.dump(clf_lda, f)\n",
    "f.close()\n",
    "\n",
    "f = open('Deployment\\Models\\RF_TFIDF_TSVD.pkl', 'wb')\n",
    "pickle.dump(clf_lsa, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84c2802",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
